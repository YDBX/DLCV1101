{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw2_1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0jk8Ph_DIUu","executionInfo":{"status":"ok","timestamp":1637405549177,"user_tz":-480,"elapsed":29885,"user":{"displayName":"YKB X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03417443848741338783"}},"outputId":"a4e0bc9f-4cd3-4388-f95a-8fc8a0ec9058"},"source":["!gdown --id 1zl2nsDqjSjHCwVnl2d_H3BPd0_HikW3P --output hw2_data.zip\n","!unzip -q hw2_data.zip\n","!rm hw2_data.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1zl2nsDqjSjHCwVnl2d_H3BPd0_HikW3P\n","To: /content/hw2_data.zip\n","100% 642M/642M [00:03<00:00, 164MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"Qu_B1f_mL1HF","executionInfo":{"status":"ok","timestamp":1637503890565,"user_tz":-480,"elapsed":25678,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}}},"source":["import glob\n","import numpy as np\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from PIL import Image\n","from torch.utils import data\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import transforms\n","from tqdm.auto import tqdm"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"XaR5X7HrWY_X"},"source":["!bash hw2_1.sh ./test_repo"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2bphntwdjsU"},"source":["def fix_random_seeds(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.enabled = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gb1w6rlwME4r"},"source":["class facedataset(data.Dataset):\n","    def __init__(self, inputs_path: list, transforms):\n","        self.inputs_path = inputs_path\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.inputs_path)\n","    \n","    def __getitem__(self, index: int):\n","        input_path = self.inputs_path[index]\n","        input = Image.open(input_path)\n","        return self.transforms(input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBQYXAiQ-yxT"},"source":["def get_dataset(batch_size, n_workers, image_size):\n","\n","    train_transforms = transforms.Compose([\n","        transforms.Resize((image_size, image_size)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","    ])\n","\n","    train_files = glob.glob('./hw2_data/face/train/*')\n","    train_files.sort()\n","    train_set = facedataset(train_files, train_transforms)\n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=n_workers, pin_memory=True)\n","\n","    return train_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eEpW6D58RMwE","executionInfo":{"status":"ok","timestamp":1637503892048,"user_tz":-480,"elapsed":456,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}}},"source":["# model\n","class EqualConv2d(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        self.scale = (2 / (in_channels * kernel_size ** 2)) ** 0.5\n","        self.conv.weight.data.normal_()\n","        self.conv.bias.data.zero_()\n","        self.bias = self.conv.bias\n","        self.conv.bias = None\n","    \n","    def forward(self, x):\n","        return self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)\n","\n","class PixelNorm(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.eps = 1e-8\n","\n","    def forward(self, x):\n","        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.eps)\n","\n","class Conv_Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, usepixelnorm=True):\n","        super().__init__()\n","        \n","        self.usepixelnorm = usepixelnorm\n","        self.pixelnorm = PixelNorm()\n","\n","        self.conv1 = nn.Sequential(\n","            EqualConv2d(in_channels, out_channels, kernel_size, stride, padding),\n","            nn.LeakyReLU(0.2),\n","        )\n","        self.conv2 = nn.Sequential(\n","            EqualConv2d(out_channels, out_channels, kernel_size, stride, padding),\n","            nn.LeakyReLU(0.2),\n","        )\n","    \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        if self.usepixelnorm:\n","            x = self.pixelnorm(x)\n","        \n","        x = self.conv2(x)\n","        if self.usepixelnorm:\n","            x = self.pixelnorm(x)\n","\n","        return x\n","\n","class Generator(nn.Module):\n","    def __init__(self, z_dim):\n","        super().__init__()\n","        self.initial_conv_block = nn.Sequential(\n","            PixelNorm(),\n","            nn.ConvTranspose2d(z_dim, z_dim, 4, 1),\n","            nn.LeakyReLU(0.2),\n","            PixelNorm(),\n","            EqualConv2d(z_dim, z_dim, kernel_size=3, stride=1, padding=1),\n","            nn.LeakyReLU(0.2),\n","            PixelNorm(),\n","        )\n","        self.initial_to_rgb = EqualConv2d(z_dim, 3, kernel_size=1, stride=1, padding=0)\n","\n","        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n","\n","        self.conv_blocks = nn.ModuleList([])\n","        self.to_rgbs = nn.ModuleList([])\n","        for i in range(len(factors) - 1):\n","            in_channels = int(z_dim * factors[i])\n","            out_channels = int(z_dim * factors[i + 1])\n","            self.conv_blocks.append(Conv_Block(in_channels, out_channels, kernel_size=3, stride=1, padding=1))\n","            self.to_rgbs.append(EqualConv2d(out_channels, 3, kernel_size=1, stride=1, padding=0))\n","\n","        self.tanh = nn.Tanh()\n","        \n","    def fade_in(self, x, alpha, depth):\n","        x_up = self.upsample(x)\n","        if depth == 1:\n","          x_scaled = self.initial_to_rgb(x_up)\n","        else:\n","          x_scaled = self.to_rgbs[depth - 2](x_up)\n","        x_conv = self.conv_blocks[depth - 1](x_up)\n","        x_conv = self.to_rgbs[depth - 1](x_conv)\n","        x = (1 - alpha) * x_scaled + alpha * x_conv\n","        x = self.tanh(x)\n","        return x\n","\n","    def forward(self, x, depth, alpha=1):\n","        \n","        x = self.initial_conv_block(x)\n","\n","        if depth == 0:\n","            x = self.initial_to_rgb(x)\n","        else:\n","            for i in range(depth - 1):\n","                x = self.upsample(x)\n","                x = self.conv_blocks[i](x)\n","            x = self.fade_in(x, alpha, depth)\n","        return x\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, z_dim):\n","        super().__init__()\n","        self.from_rgbs = nn.ModuleList([])\n","        self.conv_blocks = nn.ModuleList([])\n","        for i in range(len(factors) - 1, 0, -1):\n","            in_channels = int(z_dim * factors[i])\n","            out_channels = int(z_dim * factors[i - 1])\n","            self.from_rgbs.append(EqualConv2d(3, in_channels, kernel_size=1, stride=1, padding=0))\n","            self.conv_blocks.append(Conv_Block(in_channels, out_channels, kernel_size=3, stride=1, padding=1, usepixelnorm=False))\n","\n","        self.downsample = nn.AvgPool2d(kernel_size=2, stride=2)\n","\n","        self.final_from_rgb = EqualConv2d(3, z_dim, kernel_size=1, stride=1, padding=0)\n","\n","        self.final_conv_block = nn.Sequential(\n","            EqualConv2d(z_dim + 1, z_dim, kernel_size=3, stride=1, padding=1),\n","            nn.LeakyReLU(0.2),\n","            EqualConv2d(z_dim, z_dim, kernel_size=4, stride=1, padding=0),\n","            nn.LeakyReLU(0.2),\n","            EqualConv2d(z_dim, 1, kernel_size=1, stride=1, padding=0)\n","        )\n","        # print(self.conv_blocks)\n","        # print(self.from_rgbs)\n","\n","    def fade_in(self, x, depth, alpha=1):\n","        x_down = self.downsample(x)\n","        if depth == 1:\n","          x_scaled = self.final_from_rgb(x_down)\n","        else:\n","          x_scaled = self.from_rgbs[-depth + 1](x_down)\n","\n","        x_conv = self.from_rgbs[-depth](x)\n","        x_conv = self.conv_blocks[-depth](x_conv)\n","        x_conv = self.downsample(x_conv)\n","        # print(x_conv.shape)\n","        return (1 - alpha) * x_scaled + alpha * x_conv\n","\n","    def forward(self, x, depth, alpha=1):\n","        if depth == 0:\n","            x = self.final_from_rgb(x)\n","        else:\n","            x = self.fade_in(x, depth, alpha)\n","            for i in range(len(factors) - depth, len(factors) - 1):\n","                # print(f'i = {i}, x.shape = {x.shape}')\n","                x = self.conv_blocks[i](x)\n","                x = self.downsample(x)\n","\n","        x_std = torch.std(x, dim=0, keepdim=True).mean()\n","        concat_std = torch.ones((x.shape[0], 1, x.shape[2], x.shape[3])).to(device) * x_std\n","        x = torch.cat((x, concat_std), dim=1)\n","        x = self.final_conv_block(x)\n","        return x"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AivBhYES1kSa","executionInfo":{"status":"ok","timestamp":1637503952569,"user_tz":-480,"elapsed":317,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}},"outputId":"a1d5bc46-80b2-4c7b-fe5b-b7e7bc01a169"},"source":["z_dim = 128\n","factors = [1, 1, 1 / 2, 1 / 4, 1 / 8]\n","G = Generator(z_dim)\n","D = Discriminator(z_dim)\n","print(G)\n","print(D)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Generator(\n","  (initial_conv_block): Sequential(\n","    (0): PixelNorm()\n","    (1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n","    (2): LeakyReLU(negative_slope=0.2)\n","    (3): PixelNorm()\n","    (4): EqualConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (5): LeakyReLU(negative_slope=0.2)\n","    (6): PixelNorm()\n","  )\n","  (initial_to_rgb): EqualConv2d(\n","    (conv): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n","  (upsample): Upsample(scale_factor=2.0, mode=nearest)\n","  (conv_blocks): ModuleList(\n","    (0): Conv_Block(\n","      (pixelnorm): PixelNorm()\n","      (conv1): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","      (conv2): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (1): Conv_Block(\n","      (pixelnorm): PixelNorm()\n","      (conv1): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","      (conv2): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (2): Conv_Block(\n","      (pixelnorm): PixelNorm()\n","      (conv1): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","      (conv2): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (3): Conv_Block(\n","      (pixelnorm): PixelNorm()\n","      (conv1): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","      (conv2): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","  )\n","  (to_rgbs): ModuleList(\n","    (0): EqualConv2d(\n","      (conv): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): EqualConv2d(\n","      (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (2): EqualConv2d(\n","      (conv): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (3): EqualConv2d(\n","      (conv): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (tanh): Tanh()\n",")\n","Discriminator(\n","  (from_rgbs): ModuleList(\n","    (0): EqualConv2d(\n","      (conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (1): EqualConv2d(\n","      (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (2): EqualConv2d(\n","      (conv): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","    (3): EqualConv2d(\n","      (conv): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n","  (conv_blocks): ModuleList(\n","    (0): Conv_Block(\n","      (pixelnorm): PixelNorm()\n","      (conv1): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","      (conv2): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (1): Conv_Block(\n","      (pixelnorm): PixelNorm()\n","      (conv1): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","      (conv2): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (2): Conv_Block(\n","      (pixelnorm): PixelNorm()\n","      (conv1): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","      (conv2): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","    (3): Conv_Block(\n","      (pixelnorm): PixelNorm()\n","      (conv1): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","      (conv2): Sequential(\n","        (0): EqualConv2d(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        )\n","        (1): LeakyReLU(negative_slope=0.2)\n","      )\n","    )\n","  )\n","  (downsample): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (final_from_rgb): EqualConv2d(\n","    (conv): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  )\n","  (final_conv_block): Sequential(\n","    (0): EqualConv2d(\n","      (conv): Conv2d(129, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (1): LeakyReLU(negative_slope=0.2)\n","    (2): EqualConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    )\n","    (3): LeakyReLU(negative_slope=0.2)\n","    (4): EqualConv2d(\n","      (conv): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    )\n","  )\n",")\n"]}]},{"cell_type":"code","metadata":{"id":"j5f9VSC0-3Jg"},"source":["# gradient penalty\n","def gradient_penalty(device, D, fake_imgs, real_imgs, alpha, depth):\n","    batch_size = fake_imgs.shape[0]\n","    epsilon = torch.rand((batch_size, 1, 1, 1)).to(device)\n","    interpolate_imgs = epsilon * fake_imgs + (1 - epsilon) * real_imgs\n","    interpolate_imgs.requires_grad = True\n","    interpolate_labels = D(interpolate_imgs, depth, alpha)\n","\n","    gradient = torch.autograd.grad(outputs=interpolate_labels, inputs=interpolate_imgs, grad_outputs=torch.ones_like(interpolate_labels), allow_unused=True)[0]\n","    gradient = gradient.view(gradient.shape[0], -1)\n","    gradient_norm = gradient.norm(2, dim=1)\n","    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n","    return gradient_penalty"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvjyWtJC-5-c"},"source":["# train\n","def train(device, train_loader, start_epoch, n_epochs, depth, n_critic, z_dim, G, optim_G, D, optim_D, lambda_gp, eps_drift, z_samples):\n","    \n","    total_iters = len(train_loader) * n_epochs\n","    alpha = 0\n","    \n","    for epoch in range(start_epoch, n_epochs):\n","        \n","        G.train()\n","        D.train()\n","\n","        # train\n","        # batch_idx = 0\n","        # for imgs in tqdm(train_loader):\n","        for batch_idx, imgs in enumerate(train_loader):\n","            \n","            alpha += 1 / total_iters\n","            \n","            real_imgs = imgs\n","            real_imgs = real_imgs.to(device)\n","\n","            # Train D\n","            z = torch.randn((real_imgs.shape[0], z_dim, 1, 1)).to(device)\n","            \n","            fake_imgs = G(z, depth, alpha)\n","            \n","            fake_labels = D(fake_imgs.detach(), depth, alpha)\n","            real_labels = D(real_imgs, depth, alpha)\n","            gp = gradient_penalty(device, D, fake_imgs.detach(), real_imgs, alpha, depth)\n","            loss_D = torch.mean(fake_labels) - torch.mean(real_labels) + lambda_gp * gp + eps_drift * torch.mean(real_labels ** 2)\n","            # with open('./record.txt', 'a') as f:\n","            #     f.write(f'first_term: {torch.mean(fake_labels).item():.5f}\\n')\n","            #     f.write(f'second_term: {torch.mean(real_labels):.5f}\\n')\n","            #     f.write(f'third_term: {lambda_gp * gp:.5f}\\n')\n","            #     f.write(f'fourth_term: {eps_drift * torch.mean(real_labels ** 2):.5f}\\n')\n","\n","            D.zero_grad()\n","            loss_D.backward()\n","            optim_D.step()\n","\n","            # Train G\n","            if batch_idx % n_critic == 0:\n","                z = torch.randn((real_imgs.shape[0], z_dim, 1, 1)).to(device)\n","            \n","                fake_imgs = G(z, depth, alpha)\n","                fake_labels = D(fake_imgs, depth, alpha)\n","\n","                loss_G = -torch.mean(fake_labels)\n","\n","                G.zero_grad()\n","                loss_G.backward()\n","                optim_G.step()\n","            # batch_idx += 1\n","        with open('./record.txt', 'a') as f:\n","            f.write(f'[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss_D: {loss_D:.5f}, loss_G: {loss_G:.5f}\\n')\n","        # print(f'loss_D: {loss_D:.5f}, loss_G: {loss_G:.5f}')\n","        \n","        # evaluate\n","        G.eval()\n","        f_imgs_sample = (G(z_samples.to(device), depth).data + 1) / 2.0\n","        if not os.path.exists('./output'):\n","            os.makedirs('./output', exist_ok=True)\n","        if not os.path.exists(f'./output/{2 ** (depth + 2)}x{2 ** (depth + 2)}'):\n","            os.makedirs(f'./output/{2 ** (depth + 2)}x{2 ** (depth + 2)}')\n","        filename = os.path.join(f'./output/{2 ** (depth + 2)}x{2 ** (depth + 2)}', f'Epoch_{epoch + 1:03d}.jpg')\n","        torchvision.utils.save_image(f_imgs_sample, filename, nrow=8)\n","        # print(f'Save some samples to {filename}.')\n","        with open('./record.txt', 'a') as f:\n","            f.write(f'Save some samples to {filename}.\\n')\n","\n","        # save checkpoint\n","        torch.save({'last_epoch': epoch + 1,\n","                    'model_G': G.state_dict(),\n","                    'optim_G': optim_G.state_dict(),\n","                    'model_D': D.state_dict(),\n","                    'optim_D': optim_D.state_dict(),\n","                    'loss_G': loss_G.item(),\n","                    'loss_D': loss_D.item(),\n","                    'depth': depth,\n","                    # 'scheduler': scheduler.state_dict(),\n","                    }, f'./model_1.ckpt')\n","        \n","        with open('./record.txt', 'a') as f:\n","            f.write('Saving model\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFJK5coTlCRF"},"source":["def test(device, G, z_samples, depth, output_repo='./output_repo'):\n","    # load checkpoint\n","    ckpt = torch.load(f'./model_1.ckpt', map_location='cpu')\n","    G.load_state_dict(ckpt['model'])\n","    G.eval()\n","    \n","    # generate images\n","    generated_imgs = (G(z_samples.to(device), depth).data + 1) / 2.0\n","    for i in range(generated_imgs.shape[0]):\n","        filename = os.path.join(output_repo, f'{i}.jpg')\n","        torchvision.utils.save_image(generated_imgs[i], filename)\n","    with open('./record.txt', 'a') as f:\n","        f.write('Save 1000 generated images.\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDPQUGvO-cDR"},"source":["seed = 0\n","fix_random_seeds(seed)\n","\n","# settings\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","n_workers = 0\n","factors = [1, 1 / 2, 1 / 4, 1 / 8, 1 / 16]\n","res = [4, 8, 16, 32, 64]\n","batch_size = [32, 32, 32, 16, 16]\n","n_epochs = [80, 60, 40, 30, 30]\n","n_critic = 1\n","z_dim = 256\n","z_samples = torch.randn((1000, z_dim, 1, 1))\n","lambda_gp = 10\n","eps_drift = 0.001\n","\n","load_model = os.path.exists('./model_1.ckpt')\n","\n","G = Generator(z_dim).to(device)\n","D = Discriminator(z_dim).to(device)\n","optim_G = torch.optim.Adam(G.parameters(), lr=0.001, betas=(0, 0.99))\n","optim_D = torch.optim.Adam(D.parameters(), lr=0.001, betas=(0, 0.99))\n","\n","start_epoch = 0\n","start_depth = 0\n","\n","if load_model:\n","    ckpt = torch.load('./model_1.ckpt')\n","    start_epoch = ckpt['last_epoch']\n","    G.load_state_dict(ckpt['model_G'])\n","    optim_G.load_state_dict(ckpt['optim_G'])\n","    D.load_state_dict(ckpt['model_D'])\n","    optim_D.load_state_dict(ckpt['optim_D'])\n","    start_depth = ckpt['depth']\n","\n","with open('./record.txt', 'w') as f:\n","    f.write('')\n","\n","# training\n","# if mode == 'train':\n","\n","for i in range(start_depth, len(res)):\n","    with open('record.txt', 'a') as f:\n","        f.write(f'training {2 ** (i + 2)}x{2 ** (i + 2)}\\n')\n","    if i != start_depth:\n","      start_epoch = 0\n","    image_size = res[i]\n","    train_loader = get_dataset(batch_size[i], n_workers, image_size)\n","    train(device, train_loader, start_epoch, n_epochs[i], i, n_critic, z_dim, G, optim_G, D, optim_D, lambda_gp, eps_drift, z_samples[:32])\n","print('finish training')\n","# testing\n","\n","# if mode == 'test':\n","test(device, G, z_samples, len(res) - 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqKve33NyYA1"},"source":["# Test FID"]},{"cell_type":"code","metadata":{"id":"FGiBwXTdw3tD"},"source":["rm ./drive/MyDrive/DLCV/output_repo/*.png"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8CY2MDf3Xbh"},"source":["!mkdir './output_repo'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pdp8G0x13S9B"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z80WyNQCyXiq","executionInfo":{"status":"ok","timestamp":1637405611378,"user_tz":-480,"elapsed":5439,"user":{"displayName":"YKB X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03417443848741338783"}},"outputId":"d4e21092-6374-4e0b-ec5e-dfa78aa25fac"},"source":["!pip install pytorch-fid"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-fid\n","  Downloading pytorch-fid-0.2.1.tar.gz (14 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.19.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (7.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.4.1)\n","Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (1.10.0+cu111)\n","Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-fid) (0.11.1+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->pytorch-fid) (3.10.0.2)\n","Building wheels for collected packages: pytorch-fid\n","  Building wheel for pytorch-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch-fid: filename=pytorch_fid-0.2.1-py3-none-any.whl size=14835 sha256=27c8c8a4fac652a22d67344c7febc5b97c125caed99270db1385dec8ad1e268b\n","  Stored in directory: /root/.cache/pip/wheels/24/ac/03/c5634775c8a64f702343ef5923278f8d3bb8c651debc4a6890\n","Successfully built pytorch-fid\n","Installing collected packages: pytorch-fid\n","Successfully installed pytorch-fid-0.2.1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gOGASo1xYH-","executionInfo":{"status":"ok","timestamp":1637403717731,"user_tz":-480,"elapsed":10,"user":{"displayName":"YKB X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03417443848741338783"}},"outputId":"7ade5a60-c7ea-4cb7-a70d-22f7105c9e43"},"source":["import glob\n","files = glob.glob('./drive/MyDrive/DLCV/output_repo/*')\n","files.sort()\n","print(files)\n","print(len(files))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n","0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7I6SK19E4mzQ","executionInfo":{"status":"ok","timestamp":1637405633579,"user_tz":-480,"elapsed":9791,"user":{"displayName":"YKB X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03417443848741338783"}},"outputId":"83dc0084-7921-4730-92ac-2097daf478a0"},"source":["!bash hw2_p1.sh './output_repo'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-11-20 10:53:44--  https://www.dropbox.com/s/p6zqifenm366r05/hw2_p1.ckpt?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:601b:18::a27d:812\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/p6zqifenm366r05/hw2_p1.ckpt [following]\n","--2021-11-20 10:53:44--  https://www.dropbox.com/s/raw/p6zqifenm366r05/hw2_p1.ckpt\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uce5da45baf1f535b4185b0f0975.dl.dropboxusercontent.com/cd/0/inline/BaXX-SXlZ23IOoTpxo-R358Z2jiY-o5mOFHHTMYkYV7yOhmI8et0loI1-ek1zKUzoHdm35Um1fdgKEN_QMGFl32lAQYHSJ1vkRF-eUrvukeCp96Uty0Fg10cd3iy8543xqCNwlsylO9d6dQIaca6NLjc/file# [following]\n","--2021-11-20 10:53:45--  https://uce5da45baf1f535b4185b0f0975.dl.dropboxusercontent.com/cd/0/inline/BaXX-SXlZ23IOoTpxo-R358Z2jiY-o5mOFHHTMYkYV7yOhmI8et0loI1-ek1zKUzoHdm35Um1fdgKEN_QMGFl32lAQYHSJ1vkRF-eUrvukeCp96Uty0Fg10cd3iy8543xqCNwlsylO9d6dQIaca6NLjc/file\n","Resolving uce5da45baf1f535b4185b0f0975.dl.dropboxusercontent.com (uce5da45baf1f535b4185b0f0975.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601b:15::a27d:80f\n","Connecting to uce5da45baf1f535b4185b0f0975.dl.dropboxusercontent.com (uce5da45baf1f535b4185b0f0975.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/BaXp84sNzoVwzuiS6T9XAjQVHzu-vuUqOeKqaBaC_lk5WlxkShc82ZVPmJ96KXI09nEZqGqQiR3DZ1FMsCyb4GfFwSLhdBNkIojhQKn3Btxv_GX00fVTyV2eAds6byBUiy99tm9S2bG9swRdolUi5DcQeYukFduCYn0ZstG6IXS7wDdnB5MeUQsboXyLtOwBMfIqIJ8FbfMUssCdMNcjFFWRWcyNh42r-zsef3FeVYuf7nnjObOr7sNX3IoiWjElFxfcQ4w18mGX8RCZaeayOyFKB2DJ6md2hQzCwueifes4PrJt0isPh6QCqMvG2YzACja_0GMN9x-WQw1_c64qlJqfu_ZcSTHOTgZ6A9C5W007KVcz68Q3bZ9_Oy_iYukpTHE/file [following]\n","--2021-11-20 10:53:45--  https://uce5da45baf1f535b4185b0f0975.dl.dropboxusercontent.com/cd/0/inline2/BaXp84sNzoVwzuiS6T9XAjQVHzu-vuUqOeKqaBaC_lk5WlxkShc82ZVPmJ96KXI09nEZqGqQiR3DZ1FMsCyb4GfFwSLhdBNkIojhQKn3Btxv_GX00fVTyV2eAds6byBUiy99tm9S2bG9swRdolUi5DcQeYukFduCYn0ZstG6IXS7wDdnB5MeUQsboXyLtOwBMfIqIJ8FbfMUssCdMNcjFFWRWcyNh42r-zsef3FeVYuf7nnjObOr7sNX3IoiWjElFxfcQ4w18mGX8RCZaeayOyFKB2DJ6md2hQzCwueifes4PrJt0isPh6QCqMvG2YzACja_0GMN9x-WQw1_c64qlJqfu_ZcSTHOTgZ6A9C5W007KVcz68Q3bZ9_Oy_iYukpTHE/file\n","Reusing existing connection to uce5da45baf1f535b4185b0f0975.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22236191 (21M) [application/octet-stream]\n","Saving to: ‘hw2_p1.ckpt’\n","\n","hw2_p1.ckpt         100%[===================>]  21.21M  55.6MB/s    in 0.4s    \n","\n","2021-11-20 10:53:46 (55.6 MB/s) - ‘hw2_p1.ckpt’ saved [22236191/22236191]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbWSHTS0ydlp","executionInfo":{"status":"ok","timestamp":1637405703512,"user_tz":-480,"elapsed":63513,"user":{"displayName":"YKB X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03417443848741338783"}},"outputId":"dab91dd0-1119-4fa3-c150-d74ee38b3b12"},"source":["!python -m pytorch_fid ./hw2_data/face/test ./output_repo"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n","100% 91.2M/91.2M [00:02<00:00, 39.6MB/s]\n","100% 53/53 [00:25<00:00,  2.12it/s]\n","100% 20/20 [00:09<00:00,  2.05it/s]\n","FID:  39.6029908483398\n"]}]},{"cell_type":"markdown","metadata":{"id":"_RwQIVD9086r"},"source":["# Test IS"]},{"cell_type":"code","metadata":{"id":"S7GE1QiF08d8"},"source":["import torch\n","from torch import nn\n","from torch.autograd import Variable\n","from torch.nn import functional as F\n","import torch.utils.data\n","\n","from torchvision.models.inception import inception_v3\n","\n","import numpy as np\n","from scipy.stats import entropy\n","\n","def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n","    \"\"\"Computes the inception score of the generated images imgs\n","    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n","    cuda -- whether or not to run on GPU\n","    batch_size -- batch size for feeding into Inception v3\n","    splits -- number of splits\n","    \"\"\"\n","    N = len(imgs)\n","\n","    assert batch_size > 0\n","    assert N > batch_size\n","\n","    # Set up dtype\n","    if cuda:\n","        dtype = torch.cuda.FloatTensor\n","    else:\n","        if torch.cuda.is_available():\n","            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n","        dtype = torch.FloatTensor\n","\n","    # Set up dataloader\n","    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n","\n","    # Load inception model\n","    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n","    inception_model.eval();\n","    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n","    def get_pred(x):\n","        if resize:\n","            x = up(x)\n","        x = inception_model(x)\n","        return F.softmax(x).data.cpu().numpy()\n","\n","    # Get predictions\n","    preds = np.zeros((N, 1000))\n","\n","    for i, batch in enumerate(dataloader, 0):\n","        batch = batch.type(dtype)\n","        batchv = Variable(batch)\n","        batch_size_i = batch.size()[0]\n","\n","        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n","\n","    # Now compute the mean kl-div\n","    split_scores = []\n","\n","    for k in range(splits):\n","        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n","        py = np.mean(part, axis=0)\n","        scores = []\n","        for i in range(part.shape[0]):\n","            pyx = part[i, :]\n","            scores.append(entropy(pyx, py))\n","        split_scores.append(np.exp(np.mean(scores)))\n","\n","    return np.mean(split_scores), np.std(split_scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LryWWQuF2V-h","colab":{"base_uri":"https://localhost:8080/","height":239},"executionInfo":{"status":"error","timestamp":1637405714577,"user_tz":-480,"elapsed":15,"user":{"displayName":"YKB X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03417443848741338783"}},"outputId":"59279491-4a39-468c-cc7d-bf14c4596dca"},"source":["class facedataset(data.Dataset):\n","    def __init__(self, inputs_path: list, transforms):\n","        self.inputs_path = inputs_path\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.inputs_path)\n","    \n","    def __getitem__(self, index: int):\n","        input_path = self.inputs_path[index]\n","        input = Image.open(input_path)\n","        return self.transforms(input)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-993ed03b56a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mfacedataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]},{"cell_type":"code","metadata":{"id":"KUHH-DYf209h"},"source":["def get_dataset(batch_size, n_workers):\n","\n","    train_transforms = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","    ])\n","\n","    # test_files = glob.glob('./drive/MyDrive/DLCV/output_repo/*')\n","    test_files = glob.glob('./output_repo/*')\n","    test_files.sort()\n","    test_set = facedataset(test_files, train_transforms)\n","\n","    return test_set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvtrdyZx2_qk"},"source":["test_set = get_dataset(32, 0)\n","inception_score(test_set, cuda=torch.cuda.is_available(), batch_size=32, resize=True, splits=1)"],"execution_count":null,"outputs":[]}]}