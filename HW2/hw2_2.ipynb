{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw2_2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1SbUHtt_2Xh5NwmOfCtvWZjYmg-TkqyY7","authorship_tag":"ABX9TyMsPhMykuD2NiW0RlYe0Tor"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PQmDu7Zn3oz6"},"source":["# Download Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sOSCdVOm4MNO","executionInfo":{"status":"ok","timestamp":1637388021780,"user_tz":-480,"elapsed":34018,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}},"outputId":"7b9734b1-62de-463d-b7f2-b72f4022a388"},"source":["!gdown --id 1zl2nsDqjSjHCwVnl2d_H3BPd0_HikW3P --output hw2_data.zip\n","!unzip -q hw2_data.zip\n","!rm hw2_data.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1zl2nsDqjSjHCwVnl2d_H3BPd0_HikW3P\n","To: /content/hw2_data.zip\n","100% 642M/642M [00:03<00:00, 179MB/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"WmC38zfl3rcw"},"source":["# Bash test\n"]},{"cell_type":"code","metadata":{"id":"BVIVFKlpMeHX"},"source":["!mkdir './test_repo'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ush1IrDiwwk"},"source":["!bash hw2_p2.sh './test_repo'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02-VkRSh9kMv","executionInfo":{"status":"ok","timestamp":1637388614702,"user_tz":-480,"elapsed":282,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}},"outputId":"7e68b707-0beb-4b99-f95b-5f34b875c99a"},"source":["# %cd './output_repo'\n","# %rm *.png\n","%cd .."],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"id":"SeRdRyHe7cZb"},"source":["!python hw2_2.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c2o_Vr863Utd"},"source":["# Import Packages"]},{"cell_type":"code","metadata":{"id":"PRhYxcL_9iOs","executionInfo":{"status":"ok","timestamp":1637504573285,"user_tz":-480,"elapsed":26074,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}}},"source":["import glob\n","import numpy as np\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from PIL import Image\n","from torch.utils import data\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import transforms"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhIp4rUC3Y09"},"source":["# Define Dataset Class"]},{"cell_type":"code","metadata":{"id":"Hm6aagjD6wCN","colab":{"base_uri":"https://localhost:8080/","height":239},"executionInfo":{"status":"error","timestamp":1636681772093,"user_tz":-480,"elapsed":337,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}},"outputId":"4e81ec48-dd0e-4296-ff05-d4b04c6134e4"},"source":["# dataset class\n","class mnistm_dataset(data.Dataset):\n","    def __init__(self, inputs_path: list, labels: list, transforms):\n","        self.inputs_path = inputs_path\n","        self.labels = labels\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.inputs_path)\n","    \n","    def __getitem__(self, index: int):\n","        \n","        input_path = self.inputs_path[index]\n","        input = Image.open(input_path)\n","        label = self.labels[index]\n","\n","        return self.transforms(input), label"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8c9f7ae10e46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# dataset class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mmnistm_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"Ch3XzRKS3cvL"},"source":["# Get Dataset"]},{"cell_type":"code","metadata":{"id":"uSlxqzbm37pD"},"source":["def get_dataset(batch_size, n_workers):\n","\n","    train_transforms = transforms.Compose([\n","        # transforms.Resize((image_size, image_size)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","    ])\n","    \n","    path = './hw2_data/digits/mnistm'\n","    \n","    labels_fn = os.path.join(path, 'train.csv')\n","    labels = []\n","    with open(labels_fn, 'r') as f:\n","        for index, line in enumerate(f.readlines()):\n","            if index != 0:\n","                labels.append(int(line[-2]))\n","    \n","    train_fn = os.path.join(path, 'train/*')\n","    train_files = glob.glob(train_fn)\n","    train_files.sort()\n","    train_set = mnistm_dataset(train_files, labels, train_transforms)\n","    \n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=n_workers, pin_memory=True)\n","    \n","    return train_loader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P6Y2S4pD3fBq"},"source":["# Define Model"]},{"cell_type":"code","metadata":{"id":"ilZ0PeuW_ydI","executionInfo":{"status":"ok","timestamp":1637504573586,"user_tz":-480,"elapsed":304,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}}},"source":["def init_params(m):\n","    class_name = m.__class__.__name__\n","    if class_name.find('Conv') != -1:\n","        m.weight.data.normal_(0, 0.02)\n","        m.bias.data.zero_()\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.linear = nn.Sequential(\n","            nn.Linear(110, 256),\n","            nn.ReLU()\n","        )\n","\n","        def convt_bn_relu(in_channels, out_channels, kernel_size, stride):\n","            return nn.Sequential(\n","                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU()\n","            )\n","        self.conv_blocks = nn.Sequential(\n","            convt_bn_relu(256, 192, kernel_size=5, stride=2),\n","            convt_bn_relu(192, 96, kernel_size=5, stride=2),\n","        )\n","\n","        for conv_block in self.conv_blocks:\n","            for m in conv_block:\n","                init_params(m)\n","\n","        self.last_conv = nn.Sequential(\n","            nn.ConvTranspose2d(96, 3, kernel_size=4, stride=2),\n","            nn.Tanh()\n","        )\n","\n","        for m in self.last_conv:\n","            init_params(m)\n","\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","        x = x.view(1, x.shape[0], 1, 1)\n","        x = self.conv_blocks(x)\n","        x = self.last_conv(x)\n","        return x\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.first_conv = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=3, stride=2),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout()\n","        )\n","        \n","        for m in self.first_conv:\n","            init_params(m)\n","\n","        def conv_block(in_channels, out_channels, kernel_size, stride):\n","            return nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride),\n","                nn.BatchNorm2d(out_channels),\n","                nn.LeakyReLU(0.2),\n","                nn.Dropout()\n","            )\n","        self.conv_blocks = nn.Sequential(\n","            conv_block(16, 32, kernel_size=3, stride=1),\n","            conv_block(32, 64, kernel_size=3, stride=2),\n","        )\n","\n","        for conv_block in self.conv_blocks:\n","            for m in conv_block:\n","                init_params(m)\n","        \n","        self.linear_aux = nn.Linear(64 * 5 * 5, 10)\n","\n","        self.linear_dis = nn.Sequential(\n","            nn.Linear(64 * 5 * 5, 1),\n","            nn.Sigmoid()\n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.first_conv(x)\n","        x = self.conv_blocks(x)\n","        x = x.view(x.shape[0], -1)\n","        \n","        x_dis = self.linear_dis(x)\n","        x_aux = self.linear_aux(x)\n","        return x_dis, x_aux"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLjKklcI4FQ3","executionInfo":{"status":"ok","timestamp":1637504574307,"user_tz":-480,"elapsed":5,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}},"outputId":"1a2bf871-e756-4440-ada0-f08eb3e439aa"},"source":["G = Generator()\n","D = Discriminator()\n","print(G)\n","print(D)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Generator(\n","  (linear): Sequential(\n","    (0): Linear(in_features=110, out_features=256, bias=True)\n","    (1): ReLU()\n","  )\n","  (conv_blocks): Sequential(\n","    (0): Sequential(\n","      (0): ConvTranspose2d(256, 192, kernel_size=(5, 5), stride=(2, 2))\n","      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): ConvTranspose2d(192, 96, kernel_size=(5, 5), stride=(2, 2))\n","      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (last_conv): Sequential(\n","    (0): ConvTranspose2d(96, 3, kernel_size=(4, 4), stride=(2, 2))\n","    (1): Tanh()\n","  )\n",")\n","Discriminator(\n","  (first_conv): Sequential(\n","    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n","    (1): LeakyReLU(negative_slope=0.2)\n","    (2): Dropout(p=0.5, inplace=False)\n","  )\n","  (conv_blocks): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","      (3): Dropout(p=0.5, inplace=False)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","      (3): Dropout(p=0.5, inplace=False)\n","    )\n","  )\n","  (linear_aux): Linear(in_features=1600, out_features=10, bias=True)\n","  (linear_dis): Sequential(\n","    (0): Linear(in_features=1600, out_features=1, bias=True)\n","    (1): Sigmoid()\n","  )\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"dswBLjSm3xbT"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"6sM3uulx3wsG"},"source":["def train(device, train_loader, start_epoch, n_epochs, n_critic, z_dim, num_classes, G, optim_G, D, optim_D, z_samples, dis_loss_fn, aux_loss_fn):\n","    \n","    for epoch in range(start_epoch, n_epochs):\n","        \n","        G.train()\n","        D.train()\n","\n","        # train\n","        # batch_idx = 0\n","        # for imgs in tqdm(train_loader):\n","        for batch_idx, batch in enumerate(train_loader):\n","            \n","            \n","            real_imgs, aux_real_labels = batch\n","            real_imgs = real_imgs.to(device)\n","            cur_batch_size = real_imgs.shape[0]\n","\n","            # ============= Train D =============\n","             \n","            z_noise = torch.randn((cur_batch_size, z_dim)).to(device)\n","            aux_fake_labels = torch.randint(num_classes, (cur_batch_size, )).to(device)\n","            z_onehot = torch.zeros((cur_batch_size, num_classes)).to(device)\n","            z_onehot[np.arange(cur_batch_size), aux_fake_labels] = 1\n","            z = torch.cat([z_noise, z_onehot], dim=1).to(device)\n","            \n","            fake_imgs = G(z)\n","            \n","            dis_fake_preds, aux_fake_preds = D(fake_imgs.detach())\n","            dis_real_preds, aux_real_preds = D(real_imgs)\n","            \n","            dis_fake_labels = torch.zeros((cur_batch_size, 1)).to(device)\n","            dis_real_labels = torch.ones((cur_batch_size, 1)).to(device)\n","\n","            \n","            loss_D = dis_loss_fn(dis_fake_preds, dis_fake_labels) + aux_loss_fn(aux_fake_preds, aux_fake_labels) + \\\n","                    dis_loss_fn(dis_real_preds, dis_real_labels) + aux_loss_fn(aux_real_preds, aux_real_labels)\n","\n","            D.zero_grad()\n","            loss_D.backward()\n","            optim_D.step()\n","\n","            # ============= Train G =============\n","            if batch_idx % n_critic == 0:\n","\n","                dis_fake_preds, aux_fake_preds = D(fake_imgs)\n","\n","                loss_G = dis_loss_fn(dis_fake_preds, dis_fake_labels) + aux_loss_fn(aux_fake_preds, aux_fake_labels)\n","\n","                G.zero_grad()\n","                loss_G.backward()\n","                optim_G.step()\n","\n","            # batch_idx += 1\n","        with open('./record.txt', 'a') as f:\n","            f.write(f'[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss_D: {loss_D.item():.5f}, loss_G: {loss_G.item():.5f}\\n')\n","        # print(f'loss_D: {loss_D:.5f}, loss_G: {loss_G:.5f}')\n","        \n","        # # evaluate\n","        G.eval()\n","\n","        test_imgs = (G(z_samples).data + 1) / 2.0\n","\n","        if not os.path.exists('./output'):\n","            os.makedirs('./output', exist_ok=True)\n","\n","        filename = os.path.join('./output', f'Epoch_{epoch + 1:03d}.png')\n","        torchvision.utils.save_image(test_imgs, filename, nrow=10)\n","        # print(f'Save some samples to {filename}.')\n","        with open('./record.txt', 'a') as f:\n","            f.write(f'Save some samples to {filename}.\\n')\n","\n","        # save checkpoint\n","        torch.save({'last_epoch': epoch + 1,\n","                    'model_G': G.state_dict(),\n","                    'optim_G': optim_G.state_dict(),\n","                    'model_D': D.state_dict(),\n","                    'optim_D': optim_D.state_dict(),\n","                    # 'scheduler': scheduler.state_dict(),\n","                    }, f'./model_2.ckpt')\n","        \n","        with open('./record.txt', 'a') as f:\n","            f.write('Saving model\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QLXNAlgZ33g3"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"8n3x6piK34Z-"},"source":["def test(G, z_samples, output_repo='./output_repo'):\n","    # load checkpoint\n","    ckpt = torch.load(f'./model_2.ckpt', map_location='cpu')\n","    G.load_state_dict(ckpt['model'])\n","    G.eval()\n","    \n","    # generate images\n","    generated_imgs = (G(z_samples).data + 1) / 2.0\n","    \n","    filenames = []\n","    for label in range(10):\n","        for id in range(100):\n","            filenames.append(f'{label}_{id:03d}.png')\n","\n","    for i in range(generated_imgs.shape[0]):\n","        filename = os.path.join(output_repo, filenames[i])\n","        torchvision.utils.save_image(generated_imgs[i], filename)\n","    with open('./record.txt', 'a') as f:\n","        f.write('Save 1000 generated images.\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZfS1rW194CUx"},"source":["# Start"]},{"cell_type":"code","metadata":{"id":"Du3uUCAa38fa"},"source":["# set seed\n","seed = 0\n","fix_random_seeds(seed)\n","\n","# settings\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","n_workers = 0\n","res = 28\n","batch_size = 32\n","n_epochs = 80\n","n_critic = 1\n","z_dim = 100\n","num_classes = 10\n","\n","z_noise = torch.randn((1000, z_dim))\n","z_labels = torch.arange(10).repeat((100, ))\n","z_onehot = torch.zeros((1000, 10))\n","z_onehot[np.arange(1000), z_labels] = 1\n","z_samples = torch.cat([z_noise, z_onehot], dim=1).to(device)\n","\n","load_model = os.path.exists('./model_2.ckpt')\n","\n","G = Generator().to(device)\n","D = Discriminator().to(device)\n","optim_G = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optim_D = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","dis_loss_fn = nn.BCELoss()\n","aux_loss_fn = nn.CrossEntropyLoss()\n","\n","start_epoch = 0\n","\n","if load_model:\n","    ckpt = torch.load('./model_2.ckpt')\n","    start_epoch = ckpt['last_epoch']\n","    G.load_state_dict(ckpt['model_G'])\n","    optim_G.load_state_dict(ckpt['optim_G'])\n","    D.load_state_dict(ckpt['model_D'])\n","    optim_D.load_state_dict(ckpt['optim_D'])\n","\n","with open('./record.txt', 'w') as f:\n","    f.write('')\n","\n","# training\n","# if mode == 'train':\n","with open('record.txt', 'a') as f:\n","    f.write('start training\\n')\n","image_size = res\n","train_loader = get_dataset(batch_size, n_workers)\n","train(device, train_loader, start_epoch, n_epochs, n_critic, z_dim, num_classes, G, optim_G, D, optim_D, z_samples[:100], dis_loss_fn, aux_loss_fn)\n","with open('record.txt', 'a') as f:\n","    f.write('finish training\\n')\n","\n","# testing\n","# if mode == 'test':\n","test(G, z_samples)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ODPXLImL2v9y"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"GPFbOFDf3CC1"},"source":["class mnistm_dataset(data.Dataset):\n","    def __init__(self, inputs_path: list, labels: list, transforms):\n","        self.inputs_path = inputs_path\n","        self.labels = labels\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.inputs_path)\n","    \n","    def __getitem__(self, index: int):\n","        \n","        input_path = self.inputs_path[index]\n","        input = Image.open(input_path)\n","        label = self.labels[index]\n","\n","        return self.transforms(input), label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajwh_6j-25lZ"},"source":["def get_dataset(batch_size, n_workers):\n","\n","    train_transforms = transforms.Compose([\n","        # transforms.Resize((image_size, image_size)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","    ])\n","    \n","    train_fn = './output_repo/*'\n","    # train_fn = './drive/MyDrive/DLCV/output_repo_2/*'\n","    train_files = glob.glob(train_fn)\n","    train_files.sort()\n","    labels = [int(train_file.split('/')[-1].split('_')[0]) for train_file in train_files]\n","    train_set = mnistm_dataset(train_files, labels, train_transforms)\n","    \n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n","    \n","    return train_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNpMkB5B2vY9","executionInfo":{"status":"ok","timestamp":1637389093271,"user_tz":-480,"elapsed":10,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}},"outputId":"606a5b42-9fcd-4ce1-b999-21d3b398ce07"},"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","\n","\n","def load_checkpoint(checkpoint_path, model):\n","    state = torch.load(checkpoint_path, map_location = \"cpu\")\n","    model.load_state_dict(state['state_dict'])\n","    print('model loaded from %s' % checkpoint_path)\n","\n","\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 4 * 4, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","    \n","# load digit classifier\n","net = Classifier()\n","path = \"./drive/MyDrive/DLCV/Classifier.pth\"\n","load_checkpoint(path, net)\n","\n","# GPU enable\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print('Device used:', device)\n","if torch.cuda.is_available():\n","    net = net.to(device)\n","\n","print(net)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model loaded from ./drive/MyDrive/DLCV/Classifier.pth\n","Device used: cpu\n","Classifier(\n","  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=256, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQQF-eL64oZ9","executionInfo":{"status":"ok","timestamp":1637389093886,"user_tz":-480,"elapsed":621,"user":{"displayName":"YDBX","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiqB58Emy8lQLwFvKaZ37r6jdayWJBD3YmPSL8ag=s64","userId":"15751498837825255117"}},"outputId":"3788394c-752e-4eed-c7f3-c94730d2b531"},"source":["test_loader = get_dataset(32, 0)\n","accs = []\n","for batch in test_loader:\n","    imgs, labels = batch\n","    preds = net(imgs.to(device))\n","    print(preds.argmax(dim=1))\n","    accs.append((preds.argmax(dim=1) == labels.to(device)).float().mean())\n","print(sum(accs) / len(accs))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n","tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1])\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1])\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1])\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2])\n","tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2])\n","tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2])\n","tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3])\n","tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n","        4, 4, 4, 4, 4, 4, 4, 4])\n","tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n","        4, 4, 4, 4, 4, 4, 4, 4])\n","tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n","        4, 4, 4, 4, 4, 4, 4, 4])\n","tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5])\n","tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5])\n","tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        5, 5, 5, 5, 5, 5, 5, 5])\n","tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n","        6, 6, 6, 6, 6, 6, 6, 6])\n","tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n","        6, 6, 6, 6, 6, 6, 6, 6])\n","tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n","        6, 6, 6, 6, 6, 6, 6, 6])\n","tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n","        6, 6, 6, 6, 7, 7, 7, 7])\n","tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n","        7, 7, 7, 7, 7, 7, 7, 7])\n","tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n","        7, 7, 7, 7, 7, 7, 7, 7])\n","tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n","        7, 7, 7, 7, 7, 7, 7, 7])\n","tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n","        8, 8, 8, 8, 8, 8, 8, 8])\n","tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n","        8, 8, 8, 8, 8, 8, 8, 8])\n","tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n","        8, 8, 8, 8, 8, 8, 8, 8])\n","tensor([8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9])\n","tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9])\n","tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9])\n","tensor([9, 9, 9, 9, 9, 9, 9, 9])\n","tensor(1.)\n"]}]}]}